{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "NAME: beacon_processed\n",
    "\n",
    "PURPOSE: Create processed data for dissemination that is averaged hourly and converted to concentration units\n",
    "\n",
    "INPUTS/CHANGES REQUIRED: Change site names, site codes, start date and end date\n",
    "\n",
    "CREATED: by Kaitlyn Lieschke on 13.02.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "#import glob as glob << Need to do manually, as below\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse, tz\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List all sites to be processed\n",
    "#sitenames = np.array(['hercules','ohlone','collins','steward','montalvin','sheldon',\n",
    "#                     'middlecollege','richmondhs','peres','dejean','nystrom','madera',\n",
    "#                     'portola','verde','fieldstation','washington'])\n",
    "sitenames = np.array(['dejean','peres','richmondhs'])\n",
    "sitecodes = np.array(['DEJ_','PER_','RHS_'])\n",
    "\n",
    "# Set start and end dates for data to process\n",
    "start_date = '2017-09-01' # format YYYY-MM-DD\n",
    "start_datetime = datetime(2017,9,1)\n",
    "end_date = '2017-10-01' #Day after last day of processed data, format YYYY-MM-DD\n",
    "end_datetime = datetime(2017,10,1) #Day after last day of processed data\n",
    "\n",
    "# Set species\n",
    "spec = \"PM(ug/m3)\"\n",
    "specnm = \"%FS PM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "try:\n",
    "    _unicode = unicode\n",
    "except NameError:\n",
    "    # If Python is built without Unicode support, the unicode type\n",
    "    # will not exist. Fake one.\n",
    "    class _unicode(object):\n",
    "        pass\n",
    "__all__ = [\"glob\", \"iglob\"]\n",
    "def glob(pathname):\n",
    "    \"\"\"Return a list of paths matching a pathname pattern.\n",
    "\n",
    "    The pattern may contain simple shell-style wildcards a la\n",
    "    fnmatch. However, unlike fnmatch, filenames starting with a\n",
    "    dot are special cases that are not matched by '*' and '?'\n",
    "    patterns.\n",
    "\n",
    "    \"\"\"\n",
    "    return list(iglob(pathname))\n",
    "def iglob(pathname):\n",
    "    \"\"\"Return an iterator which yields the paths matching a pathname pattern.\n",
    "\n",
    "    The pattern may contain simple shell-style wildcards a la\n",
    "    fnmatch. However, unlike fnmatch, filenames starting with a\n",
    "    dot are special cases that are not matched by '*' and '?'\n",
    "    patterns.\n",
    "\n",
    "    \"\"\"\n",
    "    dirname, basename = os.path.split(pathname)\n",
    "    if not has_magic(pathname):\n",
    "        if basename:\n",
    "            if os.path.lexists(pathname):\n",
    "                yield pathname\n",
    "        else:\n",
    "            # Patterns ending with a slash should match only directories\n",
    "            if os.path.isdir(dirname):\n",
    "                yield pathname\n",
    "        return\n",
    "    if not dirname:\n",
    "        for name in glob1(os.curdir, basename):\n",
    "            yield name\n",
    "        return\n",
    "    # `os.path.split()` returns the argument itself as a dirname if it is a\n",
    "    # drive or UNC path.  Prevent an infinite recursion if a drive or UNC path\n",
    "    # contains magic characters (i.e. r'\\\\?\\C:').\n",
    "    if dirname != pathname and has_magic(dirname):\n",
    "        dirs = iglob(dirname)\n",
    "    else:\n",
    "        dirs = [dirname]\n",
    "    if has_magic(basename):\n",
    "        glob_in_dir = glob1\n",
    "    else:\n",
    "        glob_in_dir = glob0\n",
    "    for dirname in dirs:\n",
    "        for name in glob_in_dir(dirname, basename):\n",
    "            yield os.path.join(dirname, name)\n",
    "\n",
    "# These 2 helper functions non-recursively glob inside a literal directory.\n",
    "# They return a list of basenames. `glob1` accepts a pattern while `glob0`\n",
    "# takes a literal basename (so it only has to check for its existence).\n",
    "\n",
    "def glob1(dirname, pattern):\n",
    "    if not dirname:\n",
    "        dirname = os.curdir\n",
    "    if isinstance(pattern, _unicode) and not isinstance(dirname, unicode):\n",
    "        dirname = unicode(dirname, sys.getfilesystemencoding() or\n",
    "                                   sys.getdefaultencoding())\n",
    "    try:\n",
    "        names = os.listdir(dirname)\n",
    "    except os.error:\n",
    "        return []\n",
    "    if pattern[0] != '.':\n",
    "        names = filter(lambda x: x[0] != '.', names)\n",
    "    return fnmatch.filter(names, pattern)\n",
    "\n",
    "def glob0(dirname, basename):\n",
    "    if basename == '':\n",
    "        # `os.path.split()` returns an empty basename for paths ending with a\n",
    "        # directory separator.  'q*x/' should match only directories.\n",
    "        if os.path.isdir(dirname):\n",
    "            return [basename]\n",
    "    else:\n",
    "        if os.path.lexists(os.path.join(dirname, basename)):\n",
    "            return [basename]\n",
    "    return []\n",
    "\n",
    "\n",
    "magic_check = re.compile('[*?[]')\n",
    "\n",
    "def has_magic(s):\n",
    "    return magic_check.search(s) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create function to hourly average data\n",
    "def hourly_avg(df,datecol,pmcol):\n",
    "    df['datetime']=df[datecol].apply(lambda row: parse(row))\n",
    "    df['day'] = df['datetime'].apply(lambda x: x.day)\n",
    "    df['month'] = df['datetime'].apply(lambda x: x.month)\n",
    "    df['hour']=df['datetime'].apply(lambda x: x.hour)\n",
    "    df['year']=df['datetime'].apply(lambda x: x.year)\n",
    "    df = df.drop('datetime', axis=1)\n",
    "    df=df.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    df_t = df.groupby(['day','month','hour','year'], as_index=False,sort=False)\n",
    "    df_t = df_t.agg({pmcol:'mean'})\n",
    "    df_t['UTC time'] = df_t[['year', 'month', 'day', 'hour']].apply(lambda s : datetime(*s),axis = 1)\n",
    "    df_t = df_t[[pmcol,'UTC time']] \n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create function to generate array of datetimes at a given interval\n",
    "def date_range(start_datetime, end_datetime, increment, period):\n",
    "    result = []\n",
    "    nxt = start_datetime\n",
    "    delta = relativedelta(**{period:increment})\n",
    "    while nxt < end_datetime:\n",
    "        result.append(nxt)\n",
    "        nxt += delta\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create function to produce local datetimes (GMT-7) from UTC datetimes\n",
    "def local_datetime(df):\n",
    "    # Create new dataframe to contain local times, with length of old dataframe\n",
    "    local = pd.DataFrame(index=df.index.values, columns=['Time(GMT-7)'])\n",
    "    # Loop through all dates in df and convert to local date in new dataframe\n",
    "    for dateutc in df.index.values:\n",
    "        # Set timezones:\n",
    "        from_zone = tz.gettz('UTC')\n",
    "        to_zone = tz.gettz('America/Los_Angeles')\n",
    "        utc = df['Time(UTC)'][dateutc]\n",
    "        # Tell the datetime object that it's in UTC time zone since datetime objects are 'naive' by default\n",
    "        utc = utc.replace(tzinfo=from_zone)\n",
    "        # Convert time zone\n",
    "        local['Time(GMT-7)'][dateutc]=utc.astimezone(to_zone)\n",
    "\n",
    "    finaldf = pd.concat([local,df],axis=1)\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # List all sites to be processed\n",
    "# #sitenames = np.array(['hercules','ohlone','collins','steward','montalvin','sheldon',\n",
    "# #                     'middlecollege','richmondhs','peres','dejean','nystrom','madera',\n",
    "# #                     'portola','verde','fieldstation','washington'])\n",
    "# sitenames = np.array(['laney3','BAAQMD_sanpablo','ebmud3'])\n",
    "# sitecodes = np.array(['LAN_','BSP_','EBM_'])\n",
    "\n",
    "# # Set start and end dates for data to process\n",
    "# start_date = '2017-01-01' # format YYYY-MM-DD\n",
    "# start_datetime = datetime(2017,1,1)\n",
    "# end_date = '2018-01-01' #Day after last day of processed data, format YYYY-MM-DD\n",
    "# end_datetime = datetime(2018,1,1) #Day after last day of processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create headernames for all columns in file\n",
    "headernames=[\"BMP temperature\",\"pressure\",\"SHT temperature\",\"RH\",\"dew point temp\",\"MiCS O3\",\"MiCS CO\",\"MiCS NO2\",\n",
    "             \"Alpha O3\",\"Alpha O3\",\"Alpha CO\",\"Alpha CO\",\"Alpha NO\",\"Alpha NO\",\"Alpha NO2\",\"Alpha NO2\",\"high PM\",\n",
    "             \"lowPM\",\"%FS PM\",\"CO2\",\"GMP temperature\",\"UTC time\"]\n",
    "\n",
    "# Create array of months to iterate over when retrieving data and convert to string of YYYY_MM\n",
    "monthrange = np.array(date_range(start_datetime, end_datetime, 1, 'months'))\n",
    "for l in range(len(monthrange)):\n",
    "    monthrange[l] = monthrange[l].strftime('%Y_%m')\n",
    "\n",
    "# Create array of hourly dates\n",
    "daterange = pd.DataFrame(np.array(date_range(start_datetime, end_datetime, 1, 'hours')))\n",
    "daterange.columns = [\"Time(UTC)\"]\n",
    "\n",
    "# Download, average and combine data from all sites\n",
    "for x in range(len(sitenames)):\n",
    "    \n",
    "    #Create new column for site data in final dataframe populated with NaN\n",
    "    daterange[sitecodes[x]+spec] = np.nan\n",
    "    \n",
    "    for l in range(len(monthrange)):\n",
    "    \n",
    "        # Download and concatenate all data from one site\n",
    "        folder='/Users/kaitlynlieschke/Documents/'+sitenames[x]+'/data/'+monthrange[l]+'/'\n",
    "        files=glob(os.path.join(folder,\"*.csv\"))\n",
    "        if len(files) == 0:\n",
    "            continue\n",
    "        df=pd.concat((pd.read_csv(file,names=headernames,na_values='-999') for file in files), ignore_index=True)\n",
    "\n",
    "        #Remove any lines where date is NaN, select only relevant columns and limit dates of data\n",
    "        df=df[[specnm,'UTC time']] \n",
    "        df=df.dropna(axis=0, how='any')\n",
    "        df=df[(df['UTC time'] >= start_date) & (df['UTC time'] <= end_date)].reset_index()\n",
    "        #dflph=dflph.reset_index()   Try just adding this to the above line\n",
    "\n",
    "        #Create hourly averages of data\n",
    "        df = hourly_avg(df,'UTC time',specnm) #<< Calls hourly_avg function I created\n",
    "\n",
    "        # Loop through data in datarange to identify dates where measurements occured.\n",
    "        # Create counter (i) to follow rows in measurement dataframe df\n",
    "        i = 0\n",
    "        for j in range(len(daterange)):\n",
    "            if daterange['Time(UTC)'].iloc[j] == df['UTC time'].iloc[i]:\n",
    "                pmconc = (df[specnm].iloc[i] * 3.5)+5\n",
    "                daterange.iloc[j, daterange.columns.get_loc(sitecodes[x]+spec)] = pmconc\n",
    "                i =i+1\n",
    "                if i == len(df):\n",
    "                    break\n",
    "                \n",
    "# Add column of local datetimes to dataframe\n",
    "finaldf = local_datetime(daterange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time(GMT-7)</th>\n",
       "      <th>Time(UTC)</th>\n",
       "      <th>DEJ_CO2(ppm)</th>\n",
       "      <th>PER_CO2(ppm)</th>\n",
       "      <th>RHS_CO2(ppm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-31 17:00:00-07:00</td>\n",
       "      <td>2017-09-01 00:00:00</td>\n",
       "      <td>392.412445</td>\n",
       "      <td>403.146885</td>\n",
       "      <td>328.844166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-31 18:00:00-07:00</td>\n",
       "      <td>2017-09-01 01:00:00</td>\n",
       "      <td>409.505246</td>\n",
       "      <td>419.886463</td>\n",
       "      <td>340.356441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-31 19:00:00-07:00</td>\n",
       "      <td>2017-09-01 02:00:00</td>\n",
       "      <td>425.784389</td>\n",
       "      <td>443.212773</td>\n",
       "      <td>359.549727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-31 20:00:00-07:00</td>\n",
       "      <td>2017-09-01 03:00:00</td>\n",
       "      <td>453.873064</td>\n",
       "      <td>460.289290</td>\n",
       "      <td>356.986230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-31 21:00:00-07:00</td>\n",
       "      <td>2017-09-01 04:00:00</td>\n",
       "      <td>473.232240</td>\n",
       "      <td>476.076856</td>\n",
       "      <td>371.372380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time(GMT-7)           Time(UTC)  DEJ_CO2(ppm)  PER_CO2(ppm)  \\\n",
       "0  2017-08-31 17:00:00-07:00 2017-09-01 00:00:00    392.412445    403.146885   \n",
       "1  2017-08-31 18:00:00-07:00 2017-09-01 01:00:00    409.505246    419.886463   \n",
       "2  2017-08-31 19:00:00-07:00 2017-09-01 02:00:00    425.784389    443.212773   \n",
       "3  2017-08-31 20:00:00-07:00 2017-09-01 03:00:00    453.873064    460.289290   \n",
       "4  2017-08-31 21:00:00-07:00 2017-09-01 04:00:00    473.232240    476.076856   \n",
       "\n",
       "   RHS_CO2(ppm)  \n",
       "0    328.844166  \n",
       "1    340.356441  \n",
       "2    359.549727  \n",
       "3    356.986230  \n",
       "4    371.372380  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finaldf.to_csv(path_or_buf='SepPM.csv', sep=',', na_rep='NaN', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
